set.seed(31);
heightsCM = rnorm(30,mean=188, sd=5);
weightsK = rnorm(30,mean=84,sd=3);
hasDaughter = sample(c(TRUE,FALSE),size=30,replace=T);
dataFrame = data.frame(heightsCM,weightsK,hasDaughter);
View(dataFrame)
dataFrameSubset <- dataFrame[heightsCM > 180]
dataFrameSubset <- dataFrame[heightsCM > 180,]
View(dataFrameSubset)
View(dataFrameSubset)
View(dataFrameSubset)
dataFrameSubset <- dataFrame[heightsCM > 188,]
mean(dataFrameSubset$weightsK)
set.seed(41)
?rcauchy
cauchyValues <- rcauchy(100)
fix(cauchyValues)
set.seed(415)
?sample
sample(cauchyValues, 10, replace=TRUE)
fix(weightsK)
con <- url("http://simplystatistics.tumblr.com/", "r")
?readLines
simplyStats <- readLines(con, 150)
fix(simplyStats)
?nchar
nchar(simplyStats)
charNo <- nchar(simplyStats)
charNo(0)
charNo(1)
charNo[0]
charNo[0,]
charNo[1]
close(con)
charNo[2]
charNo[45]
charNo[122]
fileUrl <- "https://dl.dropbox.com/u/7710864/data/csv_hid/ss06hid.csv"
fileUrl <- "https://dl.dropbox.com/u/7710864/data/csv_hid/ss06hid.csv"
?download.file
getws()
wsd()
?wsd
get.ws()
download.file(fileUrl, "./Users/mihnea/Documents/Coursera/Data Analysis @John Hopkins Bloomberg University/R-workspace/source.csv", method="curl")
download.file(fileUrl, "./Users/mihnea/Documents/source.csv", method="curl")
con <- file("./Users/mihnea/Documents/source.csv", "r")
download.file(fileUrl, "./Users/mihnea/Documents/source.csv")
fileUrl <- "https://spark-public.s3.amazonaws.com/dataanalysis/ss06hid.csv"
download.file(fileUrl, "./Users/mihnea/Documents/source.csv", method="curl")
fileUrl <- "http://spark-public.s3.amazonaws.com/dataanalysis/ss06hid.csv"
download.file(fileUrl, "./Users/mihnea/Documents/source.csv", method="curl")
getwd()
download.file(fileUrl, "./Documents/source.csv", method="curl")
fileUrl <- "https://spark-public.s3.amazonaws.com/dataanalysis/ss06hid.csv"
download.file(fileUrl, "./Documents/source.csv", method="curl")
con <- file("./Documents/source.csv", "r")
communityData <- read.csv(con)
View(communityData)
nrow(communityData$VAL == 24)
nrow(communityData$VAL[:] == 24)
nrow(communityData$VAL[] == 24)
nrow(communityData$VAL[,] == 24)
communityData$VAL
communityData$VAL[] == 24
nrow(communityData$VAL[] == 24)
nrow(communityData$VAL[] == "24")
dim(communityData$VAL[] == 24)
communityData$VAL[] == 24
nrow((communityData$VAL[] == 24) == TRUE)
communityData[communityData$VAL == 24]
communityData[communityData$VAL == 24,]
count(communityData$VAL == 24)
?count
sum(communityData$VAL == 24)
table(communityData$VAL == 24)
table(communityData$VAL == 24, useNA = "ifany")
communityData$FES
table(communityData$FES)
table(communityData$FES, useNA="ifany")
sum(table(communityData$VAL == 24, useNA = "ifany"))
sum(communityData$BDS==3 & communityData$RMS==4)
table(communityData$BDS==3 & communityData$RMS==4)
table(communityData$BDS==2 & communityData$RMS==5)
table(communityData$BDS==2 & communityData$RMS==7)
agricultureLogical <- communityData$ACR==3 & communityData$AGS==6
which(agricultureLogical)
indexes <- which(agricultureLogical)
subsetDataFrame <- communityData[indexes,]
subsetDataFrame
View(subsetDataFrame)
?is.na
table(is.na(subsetDataFrame$MRGX))
?names
names(communityData)
?strsplit
strsplit(names(communityData), "wgtp")
tokens <- strsplit(names(communityData), "wgtp")
tokens[123]
tokens[[123]]
quantile(communityData$YBL)
?quantile
quantile(communityData$YBL, na.rm=TRUE)
table(communityData$YBL)
fileUrl_1 <- "https://dl.dropbox.com/u/7710864/data/csv_hid/ss06pid.csv"
download.file(fileUrl_1, "./Documents/source_1.csv", method="curl")
con_1 <- file("./Documents/source_1.csv", "r")
populationData <- read.csv(con_1)
close(con)
close(con_1)
?merge
merge(communityData, populationData, by="SERIALNO")
gigiData <- merge(communityData, populationData, by="SERIALNO")
gigiData <- merge(communityData, populationData, by="SERIALNO", all=TRUE)
library(datasets)
irisData <- data(iris)
irisData
iris
irisSub <- iris[1:4, ]
irisSub
irisSub <- iris[,1:4]
irisSub
hclustering <- hclust(irisSub)
?hclust
hClustering <- hclust(irisSub)
hClustering <- hclust(dist(irisSub))
plot(hClustering)
?hclust
hClustering <- hclust(dist(irisSub), hmin=3)
plot(hClustering, hmin=3)
?hclust
plclust(hClustering, hmin=3)
plot(hClustering, hmin=3)
?hclust
plot(hClustering, hmin = "3")
hClustering
hClustering.height
hClustering$height
hClustering$height > 3
hClustering$height >= 3
count(hClustering$height >= 3)
table(hClustering$height >= 3)
fileURL <- "https://spark-public.s3.amazonaws.com/dataanalysis/quiz3question4.rda"
getwd()
download.file(fileURL, destfile="./Documents/source.rda", method="curl")
conn = file("./Documents/source.rda")
stats = readLines(conn)
fix(stats)
load("/Users/mihnea/Documents/source.rda")
View(dataSet)
dataSet
plot(dataSet$x, dataSet$y, pch=19, col="blue", cex=0.5)
kMeansObj <- kmeans(dataSet, centers=2)
plot(x, y, col=kMeansObj$centers, pch=19, cex=2)
plot(dataSet$x, dataSet$y, col=kMeansObj$centers, pch=19, cex=2)
points(kMeansObj$centers, cole=1:2, pch=3, cex=3, lwd=3)
points(kMeansObj$centers, col=1:2, pch=3, cex=3, lwd=3)
points(kMeansObj$centers, col=1:2, pch=3, cex=3, lwd=3)
dataSet$x
plot(dataSet$x, dataSet$y, col=kMeansObj$centers, pch=19, cex=2)
points(kMeansObj$centers, col=1:2, pch=3, cex=3, lwd=3)
par(mar=rep(0.2,4))
points(kMeansObj$centers, col=1:2, pch=3, cex=3, lwd=3)
par(mar=rep(0.2,4))
plot(dataSet$x, dataSet$y, col=kMeansObj$centers, pch=19, cex=2)
points(kMeansObj$centers, col=1:2, pch=3, cex=3, lwd=3)
?plot
points(kMeansObj$centers, col=1:2, pch=3, cex=0.5)
par(mar=rep(0.2,4))
plot(dataSet$x, dataSet$y, col=kMeansObj$centers, pch=19, cex=0.5)
points(kMeansObj$centers, col=1:2, pch=3, cex=0.5)
plot(dataSet$x, dataSet$y, pch=19, col="blue", cex=0.5)
plot(dataSet$x, dataSet$y, col=kMeansObj$centers, pch=19, cex=0.5)
kMeansObj$centers
plot(dataSet$x, dataSet$y, col=kMeansObj$cluster, pch=19, cex=0.5)
points(kMeansObj$centers, col=1:2, pch=3, cex=0.5)
points(kMeansObj$centers, col=1:2, pch=3, cex=3)
?kmeans
clean
cls
clr
library(ElemStatLearn)
data(zip.train)
library(ElemStatLearn)
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
data(zip.train)
library(ElemStatLearn)
data(zip.train)
im = zip2image(zip.train,3)
image(im)
image(im)
im_8 = zip2image(zip.train,8)
im_18 = zip2image(zip.train,18)
svd_8 <- svd(im_8)
plot(svd_8$d^2/sum(svd_8$d^2),xlab="Column",ylab="Percent of variance explained",pch=19)
svd_18 <- svd(im_18)
plot(svd_18$d^2/sum(svd_18$d^2),xlab="Column",ylab="Percent of variance explained",pch=19)
plot(svd_8$d^2/sum(svd_8$d^2),xlab="Column",ylab="Percent of variance explained",pch=19)
plot(svd_18$d^2/sum(svd_18$d^2),xlab="Column",ylab="Percent of variance explained",pch=19)
image(svd_8$d)
svd_8$d
irisData <- data(iris)
hclustering <- hclust(irisSub)
irisSub <- irisData[, 1:4]
irisSub <- iris[,1:4]
hclustering <- hclust(irisSub)
hClustering <- hclust(dist(irisSub), hmin=3)
hClustering <- hclust(dist(irisSub))
plot(hClustering, hmin = "3")
plot(hClustering)
?plot
hcd <- as.dendogram(hClustering)
install.packages("phylobase")
hcd <- as.dendogram(hClustering)
cut(hClustering, h=3)
?cut
cut(hClustering, h=3)$upper
hcd <- as.dendrogram(hClustering)
plot(cut(hClustering, h=3)$upper)
plot(cut(hcd, h=3)$upper)
x <- list(2, "a", "b", TRUE)
x[[2]]
x<-c(1,3,5)
y<-c(2,3,10)
z<-rbind(x,y)
z
x<-1:4
y<-2
x+y
y<-c(1)
y<-c(2)
x+y
x <- c(3, 5, 1, 10, 12, 6)
x[x<6] <- 0
x
x<-4L
x
x<-4
x<-c(4, TRUE)
x
x <- list(2, "a", "b", TRUE)
x[1]
x[[1]
x[[1]]
y <- x[[1]]
y
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x>=10] <-4
x
x <- list(2, "a", "b", TRUE)
typeof(get(x[[1]]))
typeof(x[[1]])
typeof(x[[2]])
typeof(x[[3]])
typeof(x[[4]])
y <- x[[1]]
y
x<-c(4, TRUE)
x
z>-4L
z<-4L
typeof(z)
x <- c(3, 5, 1, 10, 12, 6)
x[x %in% 1:5] <- 0
x
library(lattice)
library(nlme)
xyplot(distance ~ age | Subject, data = Orthodont)
library(lattice)
library(nlme)
xyplot(distance ~ age | Subject, data = Orthodont, type="b")
?jpeg
?boxplot
?barchart
?boxplot
?barplot
?points
?plot
?barchart
?boxplot
?points
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?plotmath
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
?barchart
?splom
?coplot
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
set.seed(1)
rpois(5, 2)
?mtext
?lsegments
?text
?barchart
?points
?mtext
?axis
?lsegments
?text
?mtext
install.packages(c("ape", "cluster", "foreign", "KernSmooth", "lattice", "Matrix", "nlme", "nnet", "Rcpp", "rpart", "survival"))
install.packages("nltk.metrics.agreement")
install.packages("KernSmooth")
load(KernSmooth)
load("KernSmooth")
library(KernSmooth)
setwd("~/Documents/Coursera/Reproducible Research/Projects/RepData_PeerAssessment1")
read.csv("activity.csv", header = TRUE, colClasses = c("integer", "Date", "integer"))
activity.data = read.csv("activity.csv", header = TRUE, colClasses = c("integer", "Date", "integer"))
?ts
?plot.ts
?frame.plot
?axis
?ignore.NA
>plot
?plot
activity.clean = activity.data[complete.cases(activity.data),]
summary(activity.clean)
is.na(activity.clean)
count(is.na(activity.clean))
summary(activity.clean)
?na.omit
activity.clean = na.omit(activity.data)
View(activity.clean)
hist(activity.clean$steps)
?sapply
?sum
group
?group
?hist
hist(activity.clean$steps | activity.clean$date)
?tapply
tapply(activity.clean$steps, activity.clean$date, sum)
levels(activity.clean$date)
hist(tapply(activity.clean$steps, activity.clean$date, sum))
summary(tapply(activity.clean$steps, activity.clean$date, sum))
